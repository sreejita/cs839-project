{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(input_list, n):    \n",
    "    return zip(*[input_list[i:] for i in range(n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllPossibleWords(file_path): \n",
    "    possible_words=[]\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                possible_words.append(word)     \n",
    "    #possible_words = map(lambda x : unidecode.unidecode(x),possible_words)\n",
    "    for c in ['`',\"[\",\"]\",\"\\\"\",\".\",\"''\",\",\"]:\n",
    "        possible_words = map(lambda x: x.replace(c,\"\"),possible_words)\n",
    "        \n",
    "    possible_words = map(lambda x: x.replace('&','And'),possible_words)\n",
    "    #possible_words = map(lambda x: x.replace('of','Of'),possible_words)\n",
    "    possible_words=filter(lambda x:len(x)>0,possible_words)    \n",
    "    \n",
    "    return possible_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListFromFiles(filename):\n",
    "    file_path = os.path.join(os.getcwd(),filename)\n",
    "    info_list = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                info_list.append(word)\n",
    "    return info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToCsv(processed_list):\n",
    "    with open(\"output.csv\",'wb') as resultFile:\n",
    "        wr = csv.writer(resultFile, dialect='excel')\n",
    "        #for row in processed_list:\n",
    "        wr.writerows(processed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFeatures(processed_list,possible_words):\n",
    "    \n",
    "    company_suffixes = getListFromFiles(\"company-suffixes.txt\")\n",
    "    company_prefixes = getListFromFiles(\"company-prefixes.txt\")    \n",
    "    company_list=[]\n",
    "    \n",
    "    for company in processed_list:\n",
    "    \n",
    "        #Feature 1 : name has any prefix or suffix of a company \n",
    "        #if company name has any one of the suffixes or prefixes set it to true \n",
    "        hasCompanyid=0        \n",
    "        if(company[0].split()[-1] in company_suffixes or company[0].split()[0] in company_prefixes):\n",
    "            hasCompanyid = 1\n",
    "            company_list.append(company[0])            \n",
    "        #company.append(hasCompanyid)\n",
    "        \n",
    "        \n",
    "        #Feature 2 : if this name is the first word of the company name seen before \n",
    "        #has Company name at the beginning ?\n",
    "        hasCompanyNameFirst = 0\n",
    "        l1= [x for x in company[0].split() if x not in company_prefixes]\n",
    "        l2=[]\n",
    "        for comp in company_list:    \n",
    "            if(comp.split()[0] in company_prefixes):\n",
    "                l2.append(\" \".join(comp.split()[1:]))\n",
    "            else:\n",
    "                l2.append(comp)\n",
    "        if(any(word in l2 for word in l1)):\n",
    "            hasCompanyNameFirst = 1\n",
    "        elif(any(company[0].split()[0]== word.split()[0] for word in company_list)):\n",
    "            hasCompanyNameFirst = 1 \n",
    "        \n",
    "            \n",
    "        #Feature 3 : If this name is a substring of the company name seen before\n",
    "        #has Company name as a substring ?\n",
    "        hasNameSubstring=0\n",
    "        for comp in company_list:\n",
    "            l1 = company[0].split()\n",
    "            l2 = comp.split()\n",
    "            if(len(set(l1)&set(l2)) > 0 ):\n",
    "                hasNameSubstring=1       \n",
    "       \n",
    "        company.extend([hasCompanyid,hasCompanyNameFirst,hasNameSubstring])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(possible_words,doc_id):    \n",
    "    suffix_list = getListFromFiles(\"company-suffixes.txt\")\n",
    "    prefix_list = getListFromFiles(\"company-prefixes.txt\")    \n",
    "    common_words = getListFromFiles(\"common-words.txt\")\n",
    "    preprocessed_list =[]    \n",
    "    marked_list=[]\n",
    "    word_number=len(possible_words)\n",
    "    for i in range(5,0,-1):\n",
    "        word_count=0\n",
    "        ngram_list = get_ngrams(possible_words,i)\n",
    "        for ngram in ngram_list:            \n",
    "            #print ngram   \n",
    "            \n",
    "            #if markup is both at the beginning or at the end of the word group accept and label as 1\n",
    "            if(len(ngram)>1 and '<markup>' in ngram[0] and '</markup>' in ngram[len(ngram)-1] and\n",
    "              all((word[0].isupper() or \"markup\" in word) for word in ngram) and \n",
    "              [\"<markup>\" in word for word in ngram].count(True)==1): \n",
    "                company_tuple = ngram\n",
    "                for string in [\"<markup>\",\"</markup>\"]:\n",
    "                    company_tuple = map(lambda x : x.replace(string,\"\"),company_tuple)                \n",
    "                preprocessed_list.append([' '.join(company_tuple),doc_id,word_count,word_count+i-1,1])\n",
    "            \n",
    "            #get all instances of format <markup>Microsoft</markup>\n",
    "            elif(len(ngram)==1 and '</markup>' in ngram[0] and '<markup>' in ngram[0]):\n",
    "                \n",
    "                company_tuple = ngram\n",
    "                for string in [\"<markup>\",\"</markup>\"]:\n",
    "                    company_tuple = map(lambda x : x.replace(string,\"\"),company_tuple) \n",
    "                \n",
    "                preprocessed_list.append([' '.join(company_tuple),doc_id,word_count,word_count+i-1,1])            \n",
    "                    \n",
    "            else:\n",
    "                #prune away all n grams with non uppercase first character\n",
    "                if(all(word[0].isupper() and \"markup\" not in word for word in ngram)):  \n",
    "                    \n",
    "                    #prune unigrams \n",
    "                    if(i==1):                        \n",
    "                        if(ngram[0] not in suffix_list):\n",
    "                            if(word_number> word_count+1 and ngram[0] not in common_words):\n",
    "                                #add the unigram to the list if the next word begins with lower case\n",
    "                                if(possible_words[word_count+1][0].islower()):\n",
    "                                    preprocessed_list.append([' '.join(ngram),doc_id,word_count,word_count+i-1,0])\n",
    "                    \n",
    "                    #prune common words\n",
    "                    elif(any(word not in common_words for word in ngram)):                        \n",
    "                        preprocessed_list.append([' '.join(ngram),doc_id,word_count,word_count+i-1,0])                   \n",
    "\n",
    "                    \n",
    "                     \n",
    "            word_count = word_count+1\n",
    "    return preprocessed_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = os.path.dirname(os.getcwd())\n",
    "data_directory = os.path.join(base_directory,\"Dataset\",\"Rahul\",\"Final\")\n",
    "file_list = os.listdir(data_directory)\n",
    "possible_words=[]\n",
    "processed_list=[]\n",
    "count=0\n",
    "for file in file_list:\n",
    "    doc_id = file[0:3]\n",
    "    #print(doc_id)\n",
    "    #if(int(doc_id)!=1):\n",
    "     #   continue    \n",
    "    possible_words = getAllPossibleWords(os.path.join(data_directory,file))\n",
    "    \n",
    "    #start from here .. processessed list has the structure[[word,doc_id,word_count_start,word_count_end,label]]\n",
    "    processed_list_for_doc = preprocessing(possible_words,doc_id)\n",
    "    generateFeatures(processed_list_for_doc,possible_words)\n",
    "    processed_list.extend(processed_list_for_doc)\n",
    "    writeToCsv(processed_list)   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npreprocessed_list1=[]\\nngram = (\\'<markup>Barclays\\', \\'Plc</markup>\\')\\ndoc_id=1\\nword_count=1\\ni=2\\nfor string in [\"<markup>\",\"</markup>\"]:\\n    ngram = map(lambda x : x.replace(string,\"\"),ngram)\\n\\nprint(\\' \\'.join(ngram))\\npreprocessed_list1.append([\\' \\'.join(ngram),doc_id,word_count,word_count+i-1,1])\\npreprocessed_list1\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "preprocessed_list1=[]\n",
    "ngram = ('<markup>Barclays', 'Plc</markup>')\n",
    "doc_id=1\n",
    "word_count=1\n",
    "i=2\n",
    "for string in [\"<markup>\",\"</markup>\"]:\n",
    "    ngram = map(lambda x : x.replace(string,\"\"),ngram)\n",
    "\n",
    "print(' '.join(ngram))\n",
    "preprocessed_list1.append([' '.join(ngram),doc_id,word_count,word_count+i-1,1])\n",
    "preprocessed_list1\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
